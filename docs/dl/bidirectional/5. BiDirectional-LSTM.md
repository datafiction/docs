
## Bydirectional-LSTM

------


```python
from random import random
from numpy import array
from numpy import cumsum
from numpy import array_equal
```

--------


```python
# create a cumulative sum sequence
def get_sequence(n_timesteps):
  # create a sequence of random numbers in [0,1]
  X = array([random() for _ in range(n_timesteps)])
  # calculate cut-off value to change class values
  limit = n_timesteps/4.0
  # determine the class outcome for each item in cumulative sequence
  y = array([0 if x < limit else 1 for x in cumsum(X)])
  return X, y
```


```python
# create multiple samples of cumulative sum sequences
def get_sequences(n_sequences, n_timesteps):
  seqX, seqY = list(), list()
  # create and store sequences
  for _ in range(n_sequences):
    X, y = get_sequence(n_timesteps)
    seqX.append(X)
    seqY.append(y)
    
    
  # reshape input and output for lstm
  seqX = array(seqX).reshape(n_sequences, n_timesteps, 1)
  seqY = array(seqY).reshape(n_sequences, n_timesteps, 1)
  return seqX, seqY
```

### model


```python
from keras.models import Sequential
from keras.layers import LSTM
from keras.layers import Dense
from keras.layers import TimeDistributed
from keras.layers import Bidirectional
```

------


```python
# define problem
n_timesteps = 10
# define LSTM
model = Sequential()
model.add(Bidirectional(LSTM(50, return_sequences=True), input_shape=(n_timesteps, 1))) 
model.add(TimeDistributed(Dense(1, activation='sigmoid'))) 
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc']) 
print(model.summary())

```

    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    bidirectional_1 (Bidirection (None, 10, 100)           20800     
    _________________________________________________________________
    time_distributed_1 (TimeDist (None, 10, 1)             101       
    =================================================================
    Total params: 20,901
    Trainable params: 20,901
    Non-trainable params: 0
    _________________________________________________________________
    None



```python
# train LSTM
X, y = get_sequences(50000, n_timesteps)
model.fit(X, y, epochs=1, batch_size=10)

```

    Epoch 1/1
    50000/50000 [==============================] - 120s - loss: 0.0505 - acc: 0.9820   





    <keras.callbacks.History at 0x11e90d550>




```python
# evaluate LSTM
X, y = get_sequences(100, n_timesteps)
loss, acc = model.evaluate(X, y, verbose=0) 
print('Loss: %f, Accuracy: %f' % (loss, acc*100))

```

    Loss: 0.029906, Accuracy: 98.800002



```python
# make predictions
for _ in range(10):
  X, y = get_sequences(1, n_timesteps)
  yhat = model.predict_classes(X, verbose=0)
  exp, pred = y.reshape(n_timesteps), yhat.reshape(n_timesteps) 
  print('y=%s, yhat=%s, correct=%s' % (exp, pred, array_equal(exp,pred)))
```

    y=[0 0 1 1 1 1 1 1 1 1], yhat=[0 0 1 1 1 1 1 1 1 1], correct=True
    y=[0 0 0 1 1 1 1 1 1 1], yhat=[0 0 0 1 1 1 1 1 1 1], correct=True
    y=[0 0 0 1 1 1 1 1 1 1], yhat=[0 0 0 1 1 1 1 1 1 1], correct=True
    y=[0 0 0 0 0 1 1 1 1 1], yhat=[0 0 0 0 1 1 1 1 1 1], correct=False
    y=[0 0 0 0 0 0 1 1 1 1], yhat=[0 0 0 0 0 1 1 1 1 1], correct=False
    y=[0 0 0 0 0 0 1 1 1 1], yhat=[0 0 0 0 0 0 1 1 1 1], correct=True
    y=[0 0 0 0 1 1 1 1 1 1], yhat=[0 0 0 0 1 1 1 1 1 1], correct=True
    y=[0 0 0 0 0 1 1 1 1 1], yhat=[0 0 0 0 0 1 1 1 1 1], correct=True
    y=[0 0 0 1 1 1 1 1 1 1], yhat=[0 0 0 1 1 1 1 1 1 1], correct=True
    y=[0 0 0 1 1 1 1 1 1 1], yhat=[0 0 0 1 1 1 1 1 1 1], correct=True



```python

```


```python

```


```python

```
